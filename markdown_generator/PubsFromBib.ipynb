{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"proceeding\": {\n",
    "        \"file\" : \"../publications.bib\",\n",
    "        \"key\" : \"inproceedings\",\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"\",\n",
    "        \"collection\" : {\n",
    "            \"name\":\"publications\",\n",
    "            \"permalink\":\"/publication/\"\n",
    "        }\n",
    "    },\n",
    "    \"journal\": {\n",
    "        \"file\" : \"../publications.bib\",\n",
    "        \"key\" : \"article\",\n",
    "        \"venuekey\": \"journal\",\n",
    "        \"venue-pretext\": \"\",\n",
    "        \"collection\" : {\n",
    "            \"name\":\"publications\",\n",
    "            \"permalink\":\"/publication/\"\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCESSFULLY PARSED robinson2014sparse: \" Sparse Local Binary Pattern Histograms for Face Recognition  ... \"\n",
      "SUCESSFULLY PARSED jain2016: \" An Approach to Integrate Inter-dependent Simulations using H ... \"\n",
      "SUCESSFULLY PARSED robinson2016: \" Network Optimization of Food Flows in the U.S.  \"\n",
      "SUCESSFULLY PARSED robinson2017deep: \" A Deep Learning Approach for Population Estimation from Sate ... \"\n",
      "SUCESSFULLY PARSED gupta2018infrastructure: \" Infrastructure Resilience for Climate Adaptation  \"\n",
      "SUCESSFULLY PARSED robinson2018machine: \" A Machine Learning Approach to Modeling Human Migration  \"\n",
      "SUCESSFULLY PARSED robinson2018toward: \" Toward a Common Object Model for Integrated Transportation a ... \"\n",
      "SUCESSFULLY PARSED malkin2019label: \" Label Super-Resolution Networks  \"\n",
      "SUCESSFULLY PARSED robinson2019large: \" Large Scale High-Resolution Land Cover Mapping with Multi-Re ... \"\n",
      "SUCESSFULLY PARSED robinson2020human: \" Human-Machine Collaboration for Fast Land Cover Mapping  \"\n",
      "SUCESSFULLY PARSED ortiz2020local: \" Local Context Normalization: Revisiting Local Normalization  \"\n",
      "SUCESSFULLY PARSED robinson2020weakly: \" Weakly Supervised Semantic Segmentation in the 2020 IEEE GRS ... \"\n",
      "SUCESSFULLY PARSED morris2020machine: \" Machine Learning for Decision Support in Wildlife Conservati ... \"\n",
      "SUCESSFULLY PARSED robinson2021temporal: \" Temporal Cluster Matching for Change Detection of Structures ... \"\n",
      "SUCESSFULLY PARSED jojic2021local: \" From Local Algorithms to Global Results: Human-machine Colla ... \"\n",
      "SUCESSFULLY PARSED kshirsagar2021becoming: \" Becoming Good at AI for Good  \"\n",
      "SUCESSFULLY PARSED rajotte2021reducing: \" Reducing Bias and Increasing Utility by Federated Generative ... \"\n",
      "SUCESSFULLY PARSED rolf2022resolving: \" Resolving Label Uncertainty with Implicit Posterior Models  \"\n",
      "SUCESSFULLY PARSED robinson2022fast: \" Fast Building Segmentation from Satellite Imagery and Few Lo ... \"\n",
      "SUCESSFULLY PARSED stewart2022torchgeo: \" Torchgeo: Deep Learning with Geospatial Data  \"\n",
      "SUCESSFULLY PARSED gholami2022deployment: \" On the Deployment of Post-Disaster Building Damage Assessmen ... \"\n",
      "SUCESSFULLY PARSED robinson2023rapid: \" Rapid Building Damage Assessment Workflow: An Implementation ... \"\n",
      "SUCESSFULLY PARSED fobi2023poverty: \" Poverty Rate Prediction using Multi-Modal Survey and Earth O ... \"\n",
      "SUCESSFULLY PARSED robinson2017machine: \" Machine Learning Approaches for Estimating Commercial Buildi ... \"\n",
      "SUCESSFULLY PARSED zhang2018estimating: \" Estimating Residential Energy Consumption in Metropolitan Ar ... \"\n",
      "SUCESSFULLY PARSED hohman2020summit: \" SUMMIT: Scaling Deep Learning Interpretability by Visualizin ... \"\n",
      "SUCESSFULLY PARSED robinson2020modeling: \" Modeling Migration Patterns in the USA Under Sea Level Rise  \"\n",
      "SUCESSFULLY PARSED hu2020model: \" Model Generalization in Deep Learning Applications for Land  ... \"\n",
      "SUCESSFULLY PARSED malkin2021high: \" High-Resolution Land Cover Change from Low-Resolution Labels ... \"\n",
      "SUCESSFULLY PARSED yokoya2021: \" 2021 Data Fusion Contest: Geospatial Artificial Intelligence ... \"\n",
      "SUCESSFULLY PARSED robinson2021global: \" Global Land-Cover Mapping with Weak Supervision: Outcome of  ... \"\n",
      "SUCESSFULLY PARSED robinson2021detecting: \" Detecting Cattle and Elk in the Wild from Space  \"\n",
      "SUCESSFULLY PARSED yokoya2021report: \" Report on the 2021 IEEE GRSS Data Fusion Contest—Geospatial  ... \"\n",
      "SUCESSFULLY PARSED li2022outcome: \" The Outcome of the 2021 IEEE GRSS Data Fusion Contest—Track  ... \"\n",
      "SUCESSFULLY PARSED ortiz2022effective: \" Effective Deep Learning Approaches for Predicting COVID-19 O ... \"\n",
      "SUCESSFULLY PARSED robinson2022mapping: \" Mapping Industrial Poultry Operations at Scale with Deep Lea ... \"\n",
      "SUCESSFULLY PARSED ortiz2022artificial: \" An Artificial Intelligence Dataset for Solar Energy Location ... \"\n",
      "SUCESSFULLY PARSED trivedi2022deep: \" Deep Learning Models for COVID-19 Chest X-Ray Classification ... \"\n",
      "SUCESSFULLY PARSED le2023mask: \" Mask Conditional Synthetic Satellite Imagery  \"\n",
      "SUCESSFULLY PARSED khan2023biologist: \" A Biologist's Guide to the Galaxy: Leveraging Artificial Int ... \"\n",
      "SUCESSFULLY PARSED corley2023revisiting: \" Revisiting Pre-trained Remote Sensing Model Benchmarks: Resi ... \"\n",
      "SUCESSFULLY PARSED roman2023opendata: \" Open Data on GitHub: Unlocking the Potential of AI  \"\n",
      "SUCESSFULLY PARSED stewart2024ssl4eo: \" SSL4EO-L: Datasets and Foundation Models for Landsat Imagery  \"\n",
      "SUCESSFULLY PARSED manzini2023harnessing: \" Harnessing AI and Robotics in Humanitarian Assistance and Di ... \"\n",
      "SUCESSFULLY PARSED kiesecker2023road: \" The Road to India's Renewable Energy Transition Must Pass th ... \"\n",
      "SUCESSFULLY PARSED klemmer2023satclip: \" SatCLIP: Global, General-Purpose Location Embeddings with Sa ... \"\n",
      "SUCESSFULLY PARSED roman2023opendatasheets: \" Open Datasheets: Machine-readable Documentation for Open Dat ... \"\n",
      "SUCESSFULLY PARSED zaytar2024bootstrapping: \" Bootstrapping Rare Object Detection in High-Resolution Satel ... \"\n",
      "SUCESSFULLY PARSED corley2024change: \" A Change Detection Reality Check  \"\n",
      "SUCESSFULLY PARSED rolf2024mission: \" Mission Critical--Satellite Data is a Distinct Modality in M ... \"\n",
      "SUCESSFULLY PARSED hacheme2024weak: \" Weak Labeling for Cropland Mapping in Africa  \"\n",
      "SUCESSFULLY PARSED robinson2024seeing: \" Seeing the Roads Through the Trees: A Benchmark for Modeling ... \"\n"
     ]
    }
   ],
   "source": [
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    key = publist[pubsource][\"key\"]\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "\n",
    "        try:\n",
    "            pub_type = bibdata.entries[bib_id].type\n",
    "            if pub_type.lower() != key:\n",
    "                continue\n",
    "\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "            url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "            #Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            #citation authors - todo - add highlighting for primary author?\n",
    "            authors = []\n",
    "            for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "                authors.append(author.first_names[0]+\" \"+author.last_names[0])\n",
    "            citation = citation + \", \".join(authors) + \". \"\n",
    "\n",
    "            #citation title\n",
    "            citation = citation + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "            #add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "            citation = citation + \" \" + html_escape(venue)\n",
    "            citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            \n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "            \n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "            \n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "            md += \"\\nexcerpt: ''\"\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            \n",
    "            ## Markdown description for individual page\n",
    "            if url:\n",
    "                md += \"\\n[Paper](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "        \n",
    "            md += \"\\n\\nCite as: \\n```bibtex\\n\" + bibdata.entries[bib_id].to_string(\"bibtex\") + \"```\"\n",
    "\n",
    "\n",
    "            md_filename = os.path.basename(md_filename)\n",
    "\n",
    "            with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@article{robinson2024seeing,\n",
      "    author = \"Robinson, Caleb and Corley, Isaac and Ortiz, Anthony and Dodhia, Rahul and Ferres, Juan M Lavista and Najafirad, Peyman\",\n",
      "    title = \"Seeing the Roads Through the Trees: A Benchmark for Modeling Spatial Dependencies with Aerial Imagery\",\n",
      "    journal = \"arXiv preprint arXiv:2401.06762\",\n",
      "    year = \"2024\",\n",
      "    url = \"https://arxiv.org/abs/2401.06762\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bibdata.entries[bib_id].to_string(\"bibtex\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
